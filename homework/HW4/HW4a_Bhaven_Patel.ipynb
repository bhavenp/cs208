{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4A: The Local Model\n",
    "\n",
    "### Bhaven Patel\n",
    "### 4/16/2019\n",
    "\n",
    "I worked with Anthony Rentsch, Lipika Ramaswamy, and Karina Huang on this homework.\n",
    "\n",
    "My code can be found on my [Github](https://github.com/bhavenp/cs208/blob/master/homework/HW4/HW4_Bhaven_Patel.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Learning Conjunctions in the SQ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralized Version of SQ Model\n",
    "\n",
    "\n",
    "For the centralized version of the SQ model, I chose to calculate $p_j = P[x[j]=0 \\,\\wedge\\, y=1]$ for $j=1,...,d$. \n",
    "To do this, I create a \"conjunction matrix\" where the element at the $i$-th row ($i=1,...,n$) and the $j$-th column ($j=1,...,d$) contains an indicator as to whether $x_{ij}=0 \\wedge y_i=1$ in the original dataset. $p_j$ is just the mean of the $j$-th column in the conjunction matrix.\n",
    "\n",
    "Then, laplace noise is added to $p_j$ with a scale equal to $\\dfrac{GS}{\\tilde\\epsilon}$, where the global sensitivity $GS=\\dfrac{1}{n}$ and $\\tilde\\epsilon= \\dfrac{\\epsilon}{d}$. The $GS=\\dfrac{1}{n}$ because changing one value ($0\\rightarrow 1$ or $1\\rightarrow 0$) in the column $j$ changes $p_j$ by $\\dfrac{1}{n}$. Thus, every $p_j$ has a differentially private release $\\hat p_j$\n",
    "$$\n",
    "\\hat p_j = p_j + Lap\\left(\\dfrac{d}{n\\tilde\\epsilon}  \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the helper functions we generally use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\t\t# Remove any objects in memory\n",
    "\n",
    "# Random draw from Laplace distribution\n",
    "#\n",
    "# mu numeric, center of the distribution\n",
    "# b numeric, spread\n",
    "# size integer, number of draws\n",
    "# \n",
    "# return Random draws from Laplace distribution\n",
    "# example:\n",
    "# \n",
    "# rlap(size=1000)\n",
    "\n",
    "rlap = function(mu=0, b=1, size=1) {\n",
    "    p <- runif(size) - 0.5\n",
    "    draws <- mu - b * sgn(p) * log(1 - 2 * abs(p))\n",
    "    return(draws)\n",
    "}\n",
    "\n",
    "# Sign function\n",
    "# \n",
    "# Function to determine what the sign of the passed values should be.\n",
    "#\n",
    "# x numeric, value or vector or values\n",
    "# return The sign of passed values\n",
    "# example:\n",
    "#\n",
    "# sgn(rnorm(10))\n",
    "\n",
    "sgn <- function(x) {\n",
    "    return(ifelse(x < 0, -1, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to create the matrix that holds an indicator if x_j==0 & y==1\n",
    "createConjunctionMat <- function(xData, yData){\n",
    "    #create matrix to hold indicator if x_j==0 & y==1\n",
    "    result_matrix = matrix(0, nrow=nrow(xData), ncol=ncol(xData));\n",
    "    for(i in 1:nrow(xData)){\n",
    "        if(yData[i] == 1){ #only need to consider row if y=1\n",
    "            result_matrix[i, ] <- (xData[i, ] == 0); #check if x_j == 0\n",
    "        }\n",
    "    }\n",
    "    return(result_matrix);\n",
    "}\n",
    "\n",
    "#function to calculate DP-releases for each probability\n",
    "probRelease <- function(xMat, epsilon=1.0){\n",
    "    probs <- colMeans(xMat); #calculate true probabilities\n",
    "    sensitivity <- 1 / nrow(xMat); #sensitivity is 1/n\n",
    "    scale <- sensitivity / epsilon;\n",
    "    dpProbs <- probs + rlap(mu=0, b=scale, size=length(probs)); #add laplace noise to the true probabilities\n",
    "\n",
    "\treturn(list(release=dpProbs, true=probs) );\n",
    "}\n",
    "\n",
    "#function that ties together the different parts for doing a DP release of the probabilities for a \n",
    "## xData: matrix of {0,1}\n",
    "## yData: vector of {0,1}, same length as number of rows in xData\n",
    "## epsilon: total privacy-loss parameter. This will get split up by the number of columns in xData that \n",
    "##          we must release probabilities for\n",
    "## returns a list containing a vector of the indices corresponding to the columns of xData that predict yData well\n",
    "## and a vector of the DP released probabilities calculated for each column\n",
    "\n",
    "centrlDP_SQAlg <- function(xData, yData, totEpsilon=1.0, threshold=1e-4){\n",
    "    pMatrix <- createConjunctionMat(xData=xData, yData=yData); #create conjunction matrix\n",
    "#     print(totEpsilon/ncol(xData))\n",
    "    dpRelease <- probRelease(pMatrix, epsilon = totEpsilon/ncol(xData) ); #get DP release of probabilities\n",
    "#     cat(dpRelease$true);\n",
    "#     cat(dpRelease$release);\n",
    "    indices <- which(dpRelease$release < threshold); #get indices with probability less than threshold\n",
    "    return(list(indices=indices, probs=dpRelease$release) );\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$indices</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$probs</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>0.00017696776001586</li>\n",
       "\t<li>0.000207267112552507</li>\n",
       "\t<li>-5.58128522710643e-05</li>\n",
       "\t<li>0.0620781446228576</li>\n",
       "\t<li>0.0605533364523468</li>\n",
       "\t<li>0.0611838940326656</li>\n",
       "\t<li>0.0616140889946548</li>\n",
       "\t<li>0.061668819397531</li>\n",
       "\t<li>0.0608976855174546</li>\n",
       "\t<li>0.0610927852373104</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$indices] \\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$probs] \\begin{enumerate*}\n",
       "\\item 0.00017696776001586\n",
       "\\item 0.000207267112552507\n",
       "\\item -5.58128522710643e-05\n",
       "\\item 0.0620781446228576\n",
       "\\item 0.0605533364523468\n",
       "\\item 0.0611838940326656\n",
       "\\item 0.0616140889946548\n",
       "\\item 0.061668819397531\n",
       "\\item 0.0608976855174546\n",
       "\\item 0.0610927852373104\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$indices\n",
       ":   1. 1\n",
       "2. 2\n",
       "3. 3\n",
       "\n",
       "\n",
       "\n",
       "$probs\n",
       ":   1. 0.00017696776001586\n",
       "2. 0.000207267112552507\n",
       "3. -5.58128522710643e-05\n",
       "4. 0.0620781446228576\n",
       "5. 0.0605533364523468\n",
       "6. 0.0611838940326656\n",
       "7. 0.0616140889946548\n",
       "8. 0.061668819397531\n",
       "9. 0.0608976855174546\n",
       "10. 0.0610927852373104\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$indices\n",
       "[1] 1 2 3\n",
       "\n",
       "$probs\n",
       " [1]  1.769678e-04  2.072671e-04 -5.581285e-05  6.207814e-02  6.055334e-02\n",
       " [6]  6.118389e-02  6.161409e-02  6.166882e-02  6.089769e-02  6.109279e-02\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in the test data\n",
    "mydata <- read.csv('../../data/hw4testdata.csv');\n",
    "# mydata[0:10, ]\n",
    "\n",
    "#get set of features to use as predictors\n",
    "set.seed(42);\n",
    "centrlDP_SQAlg(xData = mydata[, 1:10], yData = mydata[['y']], totEpsilon = 1.0, threshold = .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe the local model set-up and how I did the correction\n",
    "\n",
    "For the local model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local release mechanism works for x as a vector. Adjusted from J. Honaker's localRelease.ipynb.\n",
    "##\n",
    "## x: vector of {0,1} for which local release must be performed\n",
    "## values: vector of length two containing the possible values in vector 'x'\n",
    "## epsilon: privacy-loss parameter to use for flipping values in 'x'\n",
    "## returns a vector\n",
    "\n",
    "localReleaseVec <- function(x, values=c(0,1), epsilon){\n",
    "\tdraws <- runif(n=length(x), min=0, max=1); #get number of draws equal to length of the vector\n",
    "\tcutoff <- 1/(1+exp(epsilon));\n",
    "    release <- x; #make a copy of the vector x\n",
    "    for(i in 1:length(x)){\n",
    "        if(draws[i] < cutoff){ #we are going to flip the our value\n",
    "            release[i] <- values[ !values %in% x[i] ] ; #create flag with (!values %in% x) for opposite value of 'x'\n",
    "        }\n",
    "    } \n",
    "    return(release);\n",
    "}\n",
    "\n",
    "\n",
    "#function that ties together the different parts for doing a DP release of the probabilities for a local model\n",
    "## xData: matrix of {0,1}\n",
    "## yData: vector of {0,1}, same length as number of rows in xData\n",
    "## epsilon: total privacy-loss parameter. This will get split up by the number of columns in xData that \n",
    "##          we must release probabilities for\n",
    "## returns a list containing a vector of the indices corresponding to the columns of xData that predict yData well\n",
    "## and a vector of the DP released probabilities calculated for each column \n",
    "\n",
    "localDP_SQAlg <- function(xData, yData, totEpsilon=1.0, threshold=1e-4){\n",
    "#     cat(paste(Sys.time(),\"\\n\") )\n",
    "    cjMatrix <- createConjunctionMat(xData=xData, yData=yData);#create conjunction matrix\n",
    "#     cat(colMeans(cjMatrix));\n",
    "    \n",
    "    epsSplit <- totEpsilon / ncol(xData); #divide the total epsilon by the number of features\n",
    "    #perform local release of conjunction matrix \n",
    "    lrMatrix <- cjMatrix; #create a copy of the conjunction matrix\n",
    "    for(r in 1:nrow(cjMatrix)){\n",
    "        lrMatrix[r, ] <- localReleaseVec(x=cjMatrix[r, ], values = c(0,1), epsilon = epsSplit);\n",
    "    }\n",
    "    \n",
    "\n",
    "    dpSums <- colSums(lrMatrix); #get sums of the local release of the conjunction matrix\n",
    "#     cat('\\n', dpSums);\n",
    "    #perform correction\n",
    "    inflation <- (exp(epsSplit) + 1) / (exp(epsSplit) - 1); #coefficient to multiply each sum by\n",
    "    n <- nrow(xData); #get number of rows\n",
    "    additive <- -n / (exp(epsSplit) - 1); #additive factor to apply for because data is {0,1}\n",
    "#     print(paste(inflation, additive))\n",
    "    dpProbs <- (dpSums * inflation + additive) / n;\n",
    "#     cat('\\n', dpProbs);\n",
    "    indices <- which(dpProbs < threshold); #get indices with probability less than threshold\n",
    "    return(list(indices=indices, probs=dpProbs));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$indices</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$probs</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>-0.0100245959057356</li>\n",
       "\t<li>-0.0558627562128042</li>\n",
       "\t<li>-0.0116259290168993</li>\n",
       "\t<li>0.083453224458464</li>\n",
       "\t<li>0.0722438926803158</li>\n",
       "\t<li>0.0502255624018109</li>\n",
       "\t<li>0.0828527245417773</li>\n",
       "\t<li>0.0898585569031199</li>\n",
       "\t<li>0.0510262289573927</li>\n",
       "\t<li>0.0758468921804347</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$indices] \\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$probs] \\begin{enumerate*}\n",
       "\\item -0.0100245959057356\n",
       "\\item -0.0558627562128042\n",
       "\\item -0.0116259290168993\n",
       "\\item 0.083453224458464\n",
       "\\item 0.0722438926803158\n",
       "\\item 0.0502255624018109\n",
       "\\item 0.0828527245417773\n",
       "\\item 0.0898585569031199\n",
       "\\item 0.0510262289573927\n",
       "\\item 0.0758468921804347\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$indices\n",
       ":   1. 1\n",
       "2. 2\n",
       "3. 3\n",
       "\n",
       "\n",
       "\n",
       "$probs\n",
       ":   1. -0.0100245959057356\n",
       "2. -0.0558627562128042\n",
       "3. -0.0116259290168993\n",
       "4. 0.083453224458464\n",
       "5. 0.0722438926803158\n",
       "6. 0.0502255624018109\n",
       "7. 0.0828527245417773\n",
       "8. 0.0898585569031199\n",
       "9. 0.0510262289573927\n",
       "10. 0.0758468921804347\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$indices\n",
       "[1] 1 2 3\n",
       "\n",
       "$probs\n",
       " [1] -0.01002460 -0.05586276 -0.01162593  0.08345322  0.07224389  0.05022556\n",
       " [7]  0.08285272  0.08985856  0.05102623  0.07584689\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(42);\n",
    "mydata <- read.csv('../../data/hw4testdata.csv');\n",
    "localDP_SQAlg(xData = mydata[, 1:10], yData = mydata[['y']], totEpsilon = 1.0, threshold = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralized DP algorithm\n",
    "\n",
    "I will refer to the $d$ columns in each dataset $x_i$ as features.<br>\n",
    "$P[\\hat S \\supseteq S]$ is the probability that set $S$ contains a feature $j$ that $\\hat S$ does not. This equivalent to determining the probability that at least one of the features $j \\in S$ has DP-released $\\hat p_j$ that is greater than the threshold $t$ we specify. Thus, we get\n",
    "$$\n",
    "P[\\hat S \\supseteq S] = \\sum_{j\\in S} P[\\hat p_j > t]\n",
    "$$\n",
    "\n",
    "For the centralized DP SQ algorithm, I chose $\\hat p_j = p_j + Lap\\left(\\dfrac{d}{n\\tilde\\epsilon}\\right)$. Additionally, we know that for each $j \\in S$, we have $p_j =0$. Thus, we get\n",
    "$$\\begin{align}\n",
    "P[\\hat S \\supseteq S] &= \\sum_{j\\in S} P[p_j + Lap\\left(\\dfrac{d}{n\\tilde\\epsilon}\\right) > t]\\\\\n",
    "&= \\sum_{j\\in S} P[0 + Lap\\left(\\dfrac{d}{n\\tilde\\epsilon}\\right) > t]\n",
    "\\end{align}$$\n",
    "\n",
    "This can be equation can be expanded to be in terms of $t$, $n$, $\\epsilon$, and $|S|$ because we can expand the probability that a value chosen from the Laplace distribution is greater than $t$ and $\\sum_{j\\in S}=|S|$:\n",
    "$$\\begin{align}\n",
    "&= \\sum_{j\\in S} P[0 + Lap\\left(\\dfrac{d}{n\\tilde\\epsilon}\\right) > t] \\\\\n",
    "&= |S| \\cdot \\int_t^{\\infty} \\dfrac{e^{(-|y|\\cdot n\\epsilon / d)}\\cdot n\\epsilon}{2d} dy\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Now, if we say that $P[\\hat S \\supseteq S] \\leq 0.1$, we can find an upper bound on what the threshold $t$ should be:\n",
    "$$\\begin{align}\n",
    "P[\\hat S \\supseteq S] &\\leq 0.1\\\\\n",
    "\\\\\n",
    "|S| \\cdot \\int_t^{\\infty} \\dfrac{e^{(-|y|\\cdot n\\epsilon / d)}\\cdot n\\epsilon}{2d} dy &\\leq 0.1\\\\\n",
    "\\\\\n",
    "|S|\\dfrac{n\\epsilon}{2d} \\cdot \\int_t^{\\infty} e^{(-|y|\\cdot n\\epsilon / d)} dy &\\leq 0.1\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\int_t^{\\infty} e^{(-|y|\\cdot n\\epsilon / d)} dy &\\leq \\dfrac{(0.1)\\cdot 2d}{|S|n\\epsilon}\\\\\n",
    "\\\\\n",
    "\\left[\\dfrac{-d}{n\\epsilon} e^{(-y\\cdot n\\epsilon / d)} \\right]_t^{\\infty} &\\leq \\dfrac{(0.1)\\cdot 2d}{|S|n\\epsilon}\\\\\n",
    "\\\\\n",
    "\\dfrac{-d}{n\\epsilon} \\left[ e^{(-\\infty \\cdot n\\epsilon / d)} - e^{(-t \\cdot n\\epsilon / d)} \\right] &\\leq \\dfrac{(0.1)\\cdot 2d}{|S|n\\epsilon}\\\\\n",
    "\\\\\n",
    "-1 \\left[ 0 - e^{(-t \\cdot n\\epsilon / d)} \\right] &\\leq \\dfrac{(0.2)}{|S|}\\\\\n",
    "\\\\\n",
    "e^{(-t \\cdot n\\epsilon / d)} &\\leq \\dfrac{(0.2)}{|S|}\\\\\n",
    "\\\\\n",
    "-t  &\\leq \\dfrac{d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)\\\\\n",
    "\\\\\n",
    "t  &\\leq \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Thus, for the centralized DP SQ algorithm, we find that $t  \\leq \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)$ if we want $P[\\hat S \\supseteq S] \\leq 0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralized DP SQ algorithm\n",
    "\n",
    "From part (b), we know that the upper bound on the threshold $t$ is $t \\leq \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)$. For the *CaPUMS5full.csv* data, we can calculate the upper bound using $n=1223992$, $d=10$, $\\epsilon = 1.0$, and $|S|=d=11$.\n",
    "$$\\begin{align}\n",
    "t &= \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)\\\\\n",
    "&= \\dfrac{10}{(1223992)(1.0)} \\log\\left(\\dfrac{(0.2)}{10} \\right)\\\\\n",
    "&= 3.20 \\cdot 10^{-5}\n",
    "\\end{align}$$\n",
    "\n",
    "Thus for the *CaPUMS5full.csv* dataset, the upper bound on the threshold $t$ is $3.20 \\cdot 10^{-5}$. I will use this threshold to show that my centralized DP SQ algorithm works on the *CaPUMS5full.csv* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"1223992  rows in CA PUMS\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>sex</th><th scope=col>married</th><th scope=col>black</th><th scope=col>asian</th><th scope=col>collegedegree</th><th scope=col>employed</th><th scope=col>militaryservice</th><th scope=col>uscitizen</th><th scope=col>disability</th><th scope=col>englishability</th><th scope=col>blackfemale</th><th scope=col>targetted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       " sex & married & black & asian & collegedegree & employed & militaryservice & uscitizen & disability & englishability & blackfemale & targetted\\\\\n",
       "\\hline\n",
       "\t 1 & 1 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0\\\\\n",
       "\t 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0\\\\\n",
       "\t 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| sex | married | black | asian | collegedegree | employed | militaryservice | uscitizen | disability | englishability | blackfemale | targetted |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 0 |\n",
       "| 1 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 |\n",
       "| 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 1 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  sex married black asian collegedegree employed militaryservice uscitizen\n",
       "1 1   1       0     0     0             1        0               1        \n",
       "2 1   1       0     0     0             0        0               1        \n",
       "3 0   1       0     0     0             0        1               1        \n",
       "  disability englishability blackfemale targetted\n",
       "1 0          1              0           0        \n",
       "2 0          1              0           0        \n",
       "3 0          1              0           0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in the test data\n",
    "caPUMS <- read.csv('../../data/CaPUMS5full.csv');\n",
    "print(paste(nrow(caPUMS), \" rows in CA PUMS\"));\n",
    "caPUMS[1:3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  6  8 10\n",
      "[1] \"employed\"       \"uscitizen\"      \"englishability\"\n"
     ]
    }
   ],
   "source": [
    "#get set of features to use as predictors\n",
    "cDPInd <- centrlDP_SQAlg(xData = caPUMS[, 1:10], yData = caPUMS[['targetted']], totEpsilon = 1.0, threshold = 3.2e-5);\n",
    "print(cDPInd$indices) #print the indices chosen as predictors for targetted\n",
    "print(colnames(caPUMS)[cDPInd$indices]) #print the colnames from the original dataset that the indices refer to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the threshold $t$ I calculated, we see that the columns *employed*, *uscitizen*, and *englishability* are the columns chosen for the set $\\hat S$.\n",
    "\n",
    "I will now use bootstraps of various sizes $n$ to compare the false positive rates and false negative rates as a function of $n$ for my centralized DP SQ algorithm. For each $n$, I will generate a bootstrapped sample and generate 10 DP releases for the set of features $\\hat S$ that predict **targetted=1**; I will calculate a false positive rate and false negative rate by predicting the value of **targetted** using the conjunction of the features included in $\\hat S$ for each of the 10 DP releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate false positive and false negative rates given true and predicted data\n",
    "calcFPandFN <- function(yTrue, yPreds){\n",
    "    numPos <- sum(yTrue); #number of positive results is just sum of the vector\n",
    "    numNeg <- length(yTrue) - numPos;\n",
    "    \n",
    "    #calculate the false negative\n",
    "    posInd <- which(yTrue == 1); #get indices of positive results\n",
    "    tps <- sum( yTrue[posInd] == yPreds[posInd]);\n",
    "    fnRate <- 1 - tps/numPos; #FN-rate is 1 - TP-rate\n",
    "    \n",
    "    #calculate the false positive\n",
    "    negInd <- which(yTrue == 0); #get indices of negative results\n",
    "    tns <- sum( yTrue[negInd] == yPreds[negInd]);\n",
    "    fpRate <- 1 - tns/numNeg; #FP-rate is 1 - TN-rate\n",
    "    \n",
    "    return(list(fp=fpRate, fn=fnRate));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set.seed(24);\n",
    "sampSizes <- c(1e2, 1e3, 5e3, 1e4, 5e4, 1e5, 5e5, 1e6); #size of datasets\n",
    "numSims <- 10; #number of simulations per bootstrap\n",
    "\n",
    "numRows <- length(sampSizes) * numSims\n",
    "resultsMatrix <- matrix(NA, nrow = numRows, ncol = 3);\n",
    "\n",
    "r = 1; #row counter\n",
    "for(sSize in sampSizes){\n",
    "    #sample the indices from the dataset\n",
    "    sample_ind <- sample(x=1:nrow(caPUMS), size=sSize, replace=TRUE);\n",
    "    bootstrap <- caPUMS[sample_ind, ]; #create a bootstrap sample\n",
    "            \n",
    "    for(i in 1:numSims){\n",
    "        cDPInd <- centrlDP_SQAlg(xData = bootstrap[, 1:10], yData = bootstrap[['targetted']], \n",
    "                                 totEpsilon = 1.0, threshold = 3.2e-5);\n",
    "        #check if no columns were selected\n",
    "        while(length(cDPInd$indices) == 0){ #re-run release if feature set is empty\n",
    "            cDPInd <- centrlDP_SQAlg(xData = bootstrap[, 1:10], yData = bootstrap[['targetted']], \n",
    "                                 totEpsilon = 1.0, threshold = 3.2e-5);\n",
    "        }\n",
    "#         print(cDPInd)\n",
    "        \n",
    "        #get the predictors specified by the bootstrap\n",
    "        bootstrapPreds <- bootstrap[, cDPInd$indices];\n",
    "        \n",
    "        if(length(cDPInd$indices) > 1){\n",
    "            #get predictions for bootstrapped sample. If conjunction of all predictors is 1,\n",
    "            #then prediction is 1.\n",
    "            yPreds <- (rowSums(bootstrapPreds) == length(cDPInd$indices) );\n",
    "        }else{ #handle case when there is just one predictor in set\n",
    "            yPreds <- bootstrapPreds;\n",
    "        }\n",
    "        \n",
    "        #get the FP and FN rates\n",
    "        stats <- calcFPandFN(yTrue=bootstrap[['targetted']], yPreds=yPreds);\n",
    "        resultsMatrix[r, ] <- c(sSize, stats$fp, stats$fn)\n",
    "        r = r+1; #increment row counter\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_results <- as.data.frame(resultsMatrix);\n",
    "colnames(final_results) <- c(\"n\", \"FPR\", \"FNR\");\n",
    "write.csv(final_results, file='ctlDP_bootstrap.csv', row.names=FALSE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local DP SQ algorithm, fill the rest out using optimal threshold\n",
    "\n",
    "From part (b), we know that the upper bound on the threshold $t$ is $t \\leq \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)$. For the *CaPUMS5full.csv* data, we can calculate the upper bound using $n=1223992$, $d=10$, $\\epsilon = 1.0$, and $|S|=d=11$.\n",
    "$$\\begin{align}\n",
    "t &= \\dfrac{-d}{n\\epsilon} \\log\\left(\\dfrac{(0.2)}{|S|} \\right)\\\\\n",
    "&= \\dfrac{10}{(1223992)(1.0)} \\log\\left(\\dfrac{(0.2)}{10} \\right)\\\\\n",
    "&= 3.20 \\cdot 10^{-5}\n",
    "\\end{align}$$\n",
    "\n",
    "Thus for the *CaPUMS5full.csv* dataset, the upper bound on the threshold $t$ is $3.20 \\cdot 10^{-5}$. I will use this threshold to show that my centralized DP SQ algorithm works on the *CaPUMS5full.csv* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 596597 588430 596150 596116 589969 581356 592187 581080 594653 581563\n",
      " 0.2481711 0.1146113 0.240861 0.240305 0.1397795 -0.001074012 0.1760517 -0.005587603 0.2163797 0.002311182[1]  6  8 10\n"
     ]
    }
   ],
   "source": [
    "localRelInd <- localDP_SQAlg(xData = mydata[, 1:10], yData = mydata[['targetted']], totEpsilon = 1.0, threshold = 1e-2);\n",
    "print(localRelInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 1 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "localReleaseVec(x = c(0,1,0), epsilon = 1.0, values = c(0,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
